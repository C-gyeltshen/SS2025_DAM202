{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c850bb3",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd39baf6",
   "metadata": {},
   "source": [
    "## Section 0: Creating Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b381367",
   "metadata": {},
   "source": [
    "### Theory Notes\n",
    "\n",
    "Before diving into preprocessing techniques, we need a sample dataset to work with. In real-world applications, text data comes from various sources like social media posts, customer reviews, documents, or web scraping results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cf9a0e",
   "metadata": {},
   "source": [
    "### Code Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98e4f8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import Pandas library\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5418ed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = [\n",
    "\n",
    "\"When life gives you lemons, make lemonade! ðŸ™‚\",\n",
    "\n",
    "\"She bought 2 lemons for $1 at Maven Market.\",\n",
    "\n",
    "\"A dozen lemons will make a gallon of lemonade. [AllRecipes]\",\n",
    "\n",
    "\"lemon, lemon, lemons, lemon, lemon, lemons\",\n",
    "\n",
    "\"He's running to the market to get a lemon â€” there's a great sale today.\",\n",
    "\n",
    "\"Does Maven Market carry Eureka lemons or Meyer lemons?\",\n",
    "\n",
    "\"An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]\",\n",
    "\n",
    "\"iced tea is my favorite\"\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a58b2dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert list to DataFrame\n",
    "\n",
    "data_df = pd.DataFrame(data, columns=['sentence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "532d363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set display options to show full content\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fdfd1a",
   "metadata": {},
   "source": [
    "## Section 1: Preprocessing\n",
    "\n",
    "### 1.1 Normalization\n",
    "\n",
    "**Theory Notes**\n",
    "\n",
    "Text normalization is the process of converting text to a standard, consistent format. The most common normalization technique is converting all text to lowercase, which ensures that words like \"Apple\" and \"apple\" are treated as the same token.\n",
    "\n",
    "### Code Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92eee323",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a copy for spaCy processing\n",
    "\n",
    "spacy_df = data_df.copy()\n",
    "\n",
    "\n",
    "\n",
    "# Convert text to lowercase\n",
    "\n",
    "spacy_df['clean_sentence'] = spacy_df['sentence'].str.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d980396d",
   "metadata": {},
   "source": [
    "### 1.2 Text Cleaning\n",
    "### Code Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be99e8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove specific citations\n",
    "\n",
    "spacy_df['clean_sentence'] = spacy_df['clean_sentence'].str.replace('[wikipedia]', '')\n",
    "\n",
    "\n",
    "\n",
    "# Advanced cleaning with regex\n",
    "\n",
    "combined = r'https?://\\S+|www\\.\\S+|<.*?>|\\S+@\\S+\\.\\S+|@\\w+|#\\w+|[^A-Za-z0-9\\s]'\n",
    "\n",
    "spacy_df['clean_sentence'] = spacy_df['clean_sentence'].str.replace(combined, ' ', regex=True)\n",
    "\n",
    "spacy_df['clean_sentence'] = spacy_df['clean_sentence'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf126e62",
   "metadata": {},
   "source": [
    "## Section 1.2: Advanced Text Processing with spaCy\n",
    "\n",
    "### Theory Notes\n",
    "\n",
    "spaCy is a powerful industrial-strength NLP library that provides advanced tokenization, lemmatization, and linguistic analysis. It offers pre-trained language models that understand grammar, syntax, and word relationships.\n",
    "\n",
    "### Code Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf82be3",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages."
     ]
    }
   ],
   "source": [
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039c0e24",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Download and install English language model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython -m spacy download en_core_web_sm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "# Download and install English language model\n",
    "\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "\n",
    "\n",
    "# Load the pre-trained pipeline\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "\n",
    "# Process a sample sentence\n",
    "\n",
    "phrase = spacy_df.clean_sentence[0] # \"when life gives you lemons make lemonade\"\n",
    "\n",
    "doc = nlp(phrase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7302880a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
